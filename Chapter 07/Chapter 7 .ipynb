{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movie review dataset\n",
    "data = pd.read_csv(\"movie_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     1000 non-null   object\n",
      " 1   sentiment  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Basic information about the dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset:\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Explore the size of the dataset (number of rows and columns)\n",
    "print(\"Size of the dataset:\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the target variable 'sentiment':\n",
      "negative    524\n",
      "positive    476\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of the target variable 'sentiment'\n",
    "print(\"Distribution of the target variable 'sentiment':\")\n",
    "print(data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manisha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Manisha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download stopwords (run this once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to clean and preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text into individual words\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join the words back into a string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply text preprocessing to the 'review' column and create a new 'cleaned_text' column\n",
    "data['cleaned_text'] = data['review'].apply(preprocess_text)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data['cleaned_text']\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "      <td>really liked summerslam due look arena curtain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>many television shows appeal quite many differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>film quickly gets major chase scene ever incre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>jane austen would definitely approve onebr br ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>expectations somewhat high went see movie thou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I really liked this Summerslam due to the look...  positive   \n",
       "1  Not many television shows appeal to quite as m...  positive   \n",
       "2  The film quickly gets to a major chase scene w...  negative   \n",
       "3  Jane Austen would definitely approve of this o...  positive   \n",
       "4  Expectations were somewhat high for me when I ...  negative   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  really liked summerslam due look arena curtain...  \n",
       "1  many television shows appeal quite many differ...  \n",
       "2  film quickly gets major chase scene ever incre...  \n",
       "3  jane austen would definitely approve onebr br ...  \n",
       "4  expectations somewhat high went see movie thou...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To view cleaned_text\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Bag-of-Words Vectorization\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BoW Representation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.75      0.81       114\n",
      "    positive       0.72      0.85      0.78        86\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.80      0.79       200\n",
      "weighted avg       0.81      0.80      0.80       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[86 28]\n",
      " [13 73]]\n",
      "\n",
      "Logistic Regression with TF-IDF Representation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       114\n",
      "    positive       0.78      0.80      0.79        86\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.82      0.82      0.82       200\n",
      "weighted avg       0.82      0.82      0.82       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95 19]\n",
      " [17 69]]\n",
      "\n",
      "Naive Bayes with BoW Representation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.90      0.87       114\n",
      "    positive       0.86      0.77      0.81        86\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.85      0.84      0.84       200\n",
      "weighted avg       0.85      0.84      0.84       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103  11]\n",
      " [ 20  66]]\n",
      "\n",
      "Naive Bayes with TF-IDF Representation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.96      0.86       114\n",
      "    positive       0.93      0.63      0.75        86\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.85      0.80      0.80       200\n",
      "weighted avg       0.84      0.82      0.81       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[110   4]\n",
      " [ 32  54]]\n",
      "\n",
      "SVM with BoW Representation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.81       114\n",
      "    positive       0.73      0.84      0.78        86\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.79      0.80      0.79       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[87 27]\n",
      " [14 72]]\n",
      "\n",
      "SVM with TF-IDF Representation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.80      0.83       114\n",
      "    positive       0.76      0.83      0.79        86\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.81      0.81       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91 23]\n",
      " [15 71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Logistic Regression for Sentiment Analysis\n",
    "# Training the model using BoW representation\n",
    "log_reg_bow = LogisticRegression()\n",
    "log_reg_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Training the model using TF-IDF representation\n",
    "log_reg_tfidf = LogisticRegression()\n",
    "log_reg_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluating Logistic Regression Models\n",
    "# Classification report and confusion matrix for BoW representation\n",
    "print(\"Logistic Regression with BoW Representation:\")\n",
    "y_pred_bow = log_reg_bow.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_bow))\n",
    "\n",
    "# Classification report and confusion matrix for TF-IDF representation\n",
    "print(\"\\nLogistic Regression with TF-IDF Representation:\")\n",
    "y_pred_tfidf = log_reg_tfidf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))\n",
    "\n",
    "# Naive Bayes for Sentiment Analysis\n",
    "# Training the model using BoW representation\n",
    "naive_bayes_bow = MultinomialNB()\n",
    "naive_bayes_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Training the model using TF-IDF representation\n",
    "naive_bayes_tfidf = MultinomialNB()\n",
    "naive_bayes_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluating Naive Bayes Models\n",
    "# Classification report and confusion matrix for BoW representation\n",
    "print(\"\\nNaive Bayes with BoW Representation:\")\n",
    "y_pred_bow_nb = naive_bayes_bow.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred_bow_nb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_bow_nb))\n",
    "\n",
    "# Classification report and confusion matrix for TF-IDF representation\n",
    "print(\"\\nNaive Bayes with TF-IDF Representation:\")\n",
    "y_pred_tfidf_nb = naive_bayes_tfidf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_tfidf_nb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tfidf_nb))\n",
    "\n",
    "# Support Vector Machine (SVM) for Sentiment Analysis\n",
    "# Training the model using BoW representation\n",
    "svm_bow = SVC()\n",
    "svm_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Training the model using TF-IDF representation\n",
    "svm_tfidf = SVC()\n",
    "svm_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluating SVM Models\n",
    "# Classification report and confusion matrix for BoW representation\n",
    "print(\"\\nSVM with BoW Representation:\")\n",
    "y_pred_bow_svm = svm_bow.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred_bow_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_bow_svm))\n",
    "\n",
    "# Classification report and confusion matrix for TF-IDF representation\n",
    "print(\"\\nSVM with TF-IDF Representation:\")\n",
    "y_pred_tfidf_svm = svm_tfidf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_tfidf_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tfidf_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
