{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Enable warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"stroke.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 4600 non-null   int64  \n",
      " 1   gender             4600 non-null   object \n",
      " 2   age                4600 non-null   float64\n",
      " 3   hypertension       4600 non-null   int64  \n",
      " 4   heart_disease      4600 non-null   int64  \n",
      " 5   ever_married       4600 non-null   object \n",
      " 6   work_type          4600 non-null   object \n",
      " 7   Residence_type     4600 non-null   object \n",
      " 8   avg_glucose_level  4600 non-null   float64\n",
      " 9   bmi                4416 non-null   float64\n",
      " 10  smoking_status     4600 non-null   object \n",
      " 11  stroke             4600 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 431.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Basic information about the dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset:\n",
      "(4600, 12)\n"
     ]
    }
   ],
   "source": [
    "# Explore the size of the dataset (number of rows and columns)\n",
    "print(\"Size of the dataset:\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "id                     0\n",
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "ever_married           0\n",
      "work_type              0\n",
      "Residence_type         0\n",
      "avg_glucose_level      0\n",
      "bmi                  184\n",
      "smoking_status         0\n",
      "stroke                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values in the 'bmi' column by filling with the mean value\n",
    "mean_bmi = data['bmi'].mean()\n",
    "data['bmi'].fillna(mean_bmi, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values after Imputation:\n",
      "id                   0\n",
      "gender               0\n",
      "age                  0\n",
      "hypertension         0\n",
      "heart_disease        0\n",
      "ever_married         0\n",
      "work_type            0\n",
      "Residence_type       0\n",
      "avg_glucose_level    0\n",
      "bmi                  0\n",
      "smoking_status       0\n",
      "stroke               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify if there are any missing values left\n",
    "print(\"\\nMissing Values after Imputation:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the target variable 'stroke':\n",
      "0    4374\n",
      "1     226\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of the target variable 'stroke'\n",
    "print(\"Distribution of the target variable 'stroke':\")\n",
    "print(data['stroke'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "data.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  hypertension  heart_disease  avg_glucose_level        bmi  stroke  \\\n",
      "0   1.72             0              0              75.79  17.600000       0   \n",
      "1  79.00             0              0             105.93  25.200000       0   \n",
      "2  28.00             0              0              87.43  55.700000       0   \n",
      "3  80.00             1              0              83.75  28.872849       0   \n",
      "4  72.00             0              0             219.91  28.872849       1   \n",
      "\n",
      "   gender_Male  gender_Other  ever_married_Yes  work_type_Never_worked  \\\n",
      "0          1.0           0.0               0.0                     0.0   \n",
      "1          1.0           0.0               1.0                     0.0   \n",
      "2          1.0           0.0               1.0                     0.0   \n",
      "3          0.0           0.0               1.0                     0.0   \n",
      "4          0.0           0.0               1.0                     0.0   \n",
      "\n",
      "   work_type_Private  work_type_Self-employed  work_type_children  \\\n",
      "0                0.0                      0.0                 1.0   \n",
      "1                0.0                      1.0                 0.0   \n",
      "2                1.0                      0.0                 0.0   \n",
      "3                1.0                      0.0                 0.0   \n",
      "4                1.0                      0.0                 0.0   \n",
      "\n",
      "   Residence_type_Urban  smoking_status_formerly smoked  \\\n",
      "0                   1.0                             0.0   \n",
      "1                   1.0                             0.0   \n",
      "2                   1.0                             0.0   \n",
      "3                   1.0                             0.0   \n",
      "4                   1.0                             0.0   \n",
      "\n",
      "   smoking_status_never smoked  smoking_status_smokes  \n",
      "0                          0.0                    0.0  \n",
      "1                          1.0                    0.0  \n",
      "2                          0.0                    0.0  \n",
      "3                          1.0                    0.0  \n",
      "4                          0.0                    0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Encode categorical features using one-hot encoding\n",
    "cat_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_features = pd.DataFrame(encoder.fit_transform(data[cat_columns]), columns=encoder.get_feature_names_out(cat_columns))\n",
    "data.drop(columns=cat_columns, inplace=True)\n",
    "data = pd.concat([data, encoded_features], axis=1)\n",
    "\n",
    "print(data.head())  # View the preprocessed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation ( without SMOTE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Evaluating Random Forest (Without SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       874\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.95       920\n",
      "   macro avg       0.47      0.50      0.49       920\n",
      "weighted avg       0.90      0.95      0.92       920\n",
      "\n",
      "Confusion Matrix for Random Forest (Without SMOTE):\n",
      "[[871   3]\n",
      " [ 46   0]]\n",
      "------------------------------------------------------------\n",
      "Training and Evaluating Gradient Boosting (Without SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       874\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.94       920\n",
      "   macro avg       0.47      0.50      0.49       920\n",
      "weighted avg       0.90      0.94      0.92       920\n",
      "\n",
      "Confusion Matrix for Gradient Boosting (Without SMOTE):\n",
      "[[868   6]\n",
      " [ 46   0]]\n",
      "------------------------------------------------------------\n",
      "Training and Evaluating Logistic Regression (Without SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       874\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.95       920\n",
      "   macro avg       0.47      0.50      0.49       920\n",
      "weighted avg       0.90      0.95      0.93       920\n",
      "\n",
      "Confusion Matrix for Logistic Regression (Without SMOTE):\n",
      "[[874   0]\n",
      " [ 46   0]]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manisha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Manisha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Manisha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Manisha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(columns=['stroke'])\n",
    "y = data['stroke']\n",
    "\n",
    "# Model Training and Evaluation (Without SMOTE)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "confusion_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Training and Evaluating Random Forest (Without SMOTE)\")\n",
    "print(report_rf)\n",
    "print(\"Confusion Matrix for Random Forest (Without SMOTE):\")\n",
    "print(confusion_rf)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "confusion_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "print(\"Training and Evaluating Gradient Boosting (Without SMOTE)\")\n",
    "print(report_gb)\n",
    "print(\"Confusion Matrix for Gradient Boosting (Without SMOTE):\")\n",
    "print(confusion_gb)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "confusion_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Training and Evaluating Logistic Regression (Without SMOTE)\")\n",
    "print(report_lr)\n",
    "print(\"Confusion Matrix for Logistic Regression (Without SMOTE):\")\n",
    "print(confusion_lr)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SMOTE to Handle Class Imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Evaluating Random Forest (With SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       874\n",
      "           1       0.99      0.96      0.98       876\n",
      "\n",
      "    accuracy                           0.98      1750\n",
      "   macro avg       0.98      0.98      0.98      1750\n",
      "weighted avg       0.98      0.98      0.98      1750\n",
      "\n",
      "Confusion Matrix for Random Forest (With SMOTE):\n",
      "[[868   6]\n",
      " [ 31 845]]\n",
      "------------------------------------------------------------\n",
      "Training and Evaluating Gradient Boosting (With SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       874\n",
      "           1       0.99      0.94      0.97       876\n",
      "\n",
      "    accuracy                           0.97      1750\n",
      "   macro avg       0.97      0.97      0.97      1750\n",
      "weighted avg       0.97      0.97      0.97      1750\n",
      "\n",
      "Confusion Matrix for Gradient Boosting (With SMOTE):\n",
      "[[868   6]\n",
      " [ 50 826]]\n",
      "------------------------------------------------------------\n",
      "Training and Evaluating Logistic Regression (With SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       874\n",
      "           1       0.76      0.80      0.78       876\n",
      "\n",
      "    accuracy                           0.78      1750\n",
      "   macro avg       0.78      0.78      0.78      1750\n",
      "weighted avg       0.78      0.78      0.78      1750\n",
      "\n",
      "Confusion Matrix for Logistic Regression (With SMOTE):\n",
      "[[656 218]\n",
      " [174 702]]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manisha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Handling ClasApplying SMOTE to Handle Class Imbalance:s Imbalance with SMOTE\n",
    "X = data.drop(columns=['stroke'])\n",
    "y = data['stroke']\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into features (X) and target (y) for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training and Evaluation\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "confusion_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Training and Evaluating Random Forest (With SMOTE)\")\n",
    "print(report_rf)\n",
    "print(\"Confusion Matrix for Random Forest (With SMOTE):\")\n",
    "print(confusion_rf)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "confusion_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "print(\"Training and Evaluating Gradient Boosting (With SMOTE)\")\n",
    "print(report_gb)\n",
    "print(\"Confusion Matrix for Gradient Boosting (With SMOTE):\")\n",
    "print(confusion_gb)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "confusion_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Training and Evaluating Logistic Regression (With SMOTE)\")\n",
    "print(report_lr)\n",
    "print(\"Confusion Matrix for Logistic Regression (With SMOTE):\")\n",
    "print(confusion_lr)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
